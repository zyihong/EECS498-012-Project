{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(Generator, self).__init__()\n",
    "        #input size (6,256,256)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(6,32,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(3,stride=2,padding=1))\n",
    "        #(3,128,128)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(3,stride=2,padding=1))\n",
    "        #(64,64,64)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128,128,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(3,stride=2,padding=1))\n",
    "        #(128,32,32)\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256,256,kernel_size,stride = 1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(3,stride=2,padding=1))\n",
    "        #(256,16,16)\n",
    "        self.deconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256,128,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128,128,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        #(128,32,32)\n",
    "        self.deconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256,64,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        #(64,64,64)\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,32,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        #(3,256,256)\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,3,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(3,3,kernel_size,stride = 1, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        e1 = self.conv1(inputs)\n",
    "        e2 = self.conv2(e1)\n",
    "        e3 = self.conv3(e2)\n",
    "        e4 = self.conv4(e3)\n",
    "        d4 = self.deconv4(e4)\n",
    "        d3_in = torch.cat((e3,d4),1)\n",
    "        d3 = self.deconv3(d3_in)\n",
    "        d2_in = torch.cat((e2,d3),1)\n",
    "        d2 = self.deconv2(d2_in)\n",
    "        d1_in = torch.cat((e1,d2),1)\n",
    "        d1 = self.deconv1(d1_in)\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 240, 320])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emily/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/emily/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "#test Generator\n",
    "inputs = torch.rand((10,6,240,320))\n",
    "model = Generator()\n",
    "outputs = model.forward(inputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=5, dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dim = dim\n",
    "        self.conv1 = nn.Conv2d(3, self.dim, self.kernel_size, stride=2, padding=2)\n",
    "        #(64,120,160)\n",
    "        #LeakyRelu\n",
    "        self.conv2 = nn.Conv2d(self.dim, 2*self.dim,kernel_size,stride=2,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(2*self.dim)\n",
    "        #LeakyRelu\n",
    "        #(128,60,80)\n",
    "        self.conv3 = nn.Conv2d(2*self.dim,4*self.dim,kernel_size,stride=2,padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(4*self.dim)\n",
    "        #LeakyRelu\n",
    "        #(256,30,40)\n",
    "        self.conv4 = nn.Conv2d(4*self.dim,8*self.dim,kernel_size,stride=2,padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8*self.dim)\n",
    "        #LeakyRelu\n",
    "        #(512,15,20)\n",
    "        self.conv5 = nn.Conv2d(8*self.dim,8*self.dim,kernel_size,stride=2,padding=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8*self.dim)\n",
    "        #LeakyRelu\n",
    "        #(512,8,10)\n",
    "        self.fc = nn.Linear(8*10*8*self.dim,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        output = self.conv1(x)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn1(output)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn2(output)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.conv4(output)\n",
    "        output = self.bn3(output)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.conv5(output)\n",
    "        output = self.bn4(output)\n",
    "        output = F.leaky_relu(output)\n",
    "        \n",
    "        output = output.view(-1, 8*10*8*self.dim)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2042]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test discriminator\n",
    "x = torch.rand((1,3,240,320))\n",
    "model = Discriminator()\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_criterion = nn.L1Loss()\n",
    "BCE_criterion = nn.BCELoss()\n",
    "#generator_one = GeneratorCNN_Pose_UAEAfterResidual_256(21, z_num, repeat_num)\n",
    "generator_two = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "gen_train_op2 = optim.Adam(generator_two.parameters(), lr=2e-5, betas=(0.5, 0.999))\n",
    "dis_train_op1 = optim.Adam(discriminator.parameters(), lr=2e-5, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(10):\n",
    "        for step, example in enumerate(pose_loader):\n",
    "            [x, x_target, mask_target] = example\n",
    "            x = Variable(x.cuda())\n",
    "            x_target = Variable(x_target.cuda())\n",
    "            mask_target = Variable(mask_target.cuda())\n",
    "            \n",
    "            \n",
    "            \n",
    "            DiffMap = generator_two(torch.cat([G1, x], dim=1))\n",
    "            G2 = G1 + DiffMap\n",
    "            triplet = torch.cat([x_target, G2, x], dim=0)\n",
    "            D_z = Discriminator(triplet)\n",
    "            D_z_pos_x_target, D_z_neg_g2, D_z_neg_x = torch.split(D_z, 3)\n",
    "            D_z_pos = D_z_pos_x_target\n",
    "            D_z_neg = torch.cat([D_z_neg_g2, D_z_neg_x], 0)\n",
    "            \n",
    "            g_loss_2 = BCE_criterion(D_z_neg, torch.ones((2)).cuda())\n",
    "            PoseMaskLoss2 = L1_criterion(G2 * mask_target, x_target * mask_target)\n",
    "            L1Loss2 = L1_criterion(G2, x_target) + PoseMaskLoss2\n",
    "            g_loss_2 += 50*L1Loss2\n",
    "\n",
    "            gen_train_op2.zero_grad()\n",
    "            g_loss_2.backward()\n",
    "            gen_train_op2.step(retain_graph=True)\n",
    "\n",
    "            d_loss = BCE_criterion(D_z_pos, torch.ones((1)).cuda())\n",
    "            d_loss += BCE_criterion(D_z_neg, torch.zeros((2)).cuda())\n",
    "            d_loss /= 2\n",
    "            \n",
    "            dis_train_op1.zero_grad()\n",
    "            d_loss.backward()\n",
    "            dis_train_op1.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
